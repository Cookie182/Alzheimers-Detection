{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16593d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.095078Z",
     "start_time": "2021-12-23T19:51:21.657354Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3512fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.143069Z",
     "start_time": "2021-12-23T19:51:24.097057Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "f\"device being used -> {device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30275a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.159072Z",
     "start_time": "2021-12-23T19:51:24.145073Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = pathlib.Path(\"./Alzheimer_s Dataset\")\n",
    "\n",
    "train_dataset_dir = dataset_dir / \"train\"\n",
    "test_dataset_dir = dataset_dir / \"test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # automatically applies min/max scaling\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "classes = [x.parts[-1] for x in train_dataset_dir.iterdir()]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f65345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.335112Z",
     "start_time": "2021-12-23T19:51:24.161074Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating pipelines to load in overall data\n",
    "train_dataset = ImageFolder(root=train_dataset_dir, transform=transform)\n",
    "plt.title(train_dataset.classes[train_dataset[0][1]])\n",
    "plt.imshow(train_dataset[0][0][0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "IMG_DIM = train_dataset[0][0].size()[1:]\n",
    "print(f\"image dimension -> {IMG_DIM}\")\n",
    "\n",
    "# defining validation data proportion\n",
    "validation_split = 0.1\n",
    "validation_images = int(len(train_dataset) * validation_split)\n",
    "train_images = len(train_dataset) - validation_images\n",
    "\n",
    "# defining training/validation/testing datasets\n",
    "train_dataset, val_dataset = random_split(train_dataset, (train_images, validation_images),\n",
    "                                         generator=torch.Generator().manual_seed(182))\n",
    "\n",
    "train_dataset = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dataset = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = DataLoader(dataset=ImageFolder(root=test_dataset_dir, transform=transform), \n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"train images -> {len(train_dataset) * batch_size}\")\n",
    "print(f\"validation images -> {len(val_dataset) * batch_size}\")\n",
    "print(f\"test images -> {len(test_dataset) * batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1164f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.351115Z",
     "start_time": "2021-12-23T19:51:24.337115Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAct(nn.Module):\n",
    "    \"\"\"Convolution block layer that includes batch normalization and a max pooling layer\"\"\"\n",
    "    def __init__(self, in_fitlers, out_filters, kernel_size=3, stride=1, dropout=None):\n",
    "        super(ConvAct, self).__init__()\n",
    "        self.in_filters = in_fitlers\n",
    "        self.out_filters = out_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv_layer= nn.Conv2d(in_channels=self.in_filters, out_channels=self.out_filters, \n",
    "                                     kernel_size=self.kernel_size, stride=self.stride)\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.batchnorm = nn.BatchNorm2d(num_features=self.out_filters)\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        if self.dropout != None:\n",
    "            self.dropout_layer = nn.Dropout2d(self.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.act(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.maxpooling(x)\n",
    "        if self.dropout != None:\n",
    "            x = self.dropout_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d416fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.367119Z",
     "start_time": "2021-12-23T19:51:24.353118Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearAct(nn.Module):\n",
    "    \"\"\"Fully connected layer block which includes batch normalization and optional dropout layers\"\"\"\n",
    "    def __init__(self, in_features, out_features, output_layer=False, dropout=None):\n",
    "        super(LinearAct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.output_layer = output_layer\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.fc = nn.Linear(in_features=self.in_features, out_features=self.out_features)\n",
    "        if self.output_layer == False:\n",
    "            self.batchnorm = nn.BatchNorm1d(num_features=self.out_features)\n",
    "            self.act = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "        if self.dropout != None:\n",
    "            self.dropout_layer = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.output_layer == False:\n",
    "            x = self.fc(x)\n",
    "            x = self.act(x)\n",
    "            x = self.batchnorm(x)\n",
    "            if self.dropout != None:\n",
    "                x = self.dropout_layer(x)\n",
    "        else:\n",
    "            x = self.fc(x)\n",
    "            x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186d8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.383123Z",
     "start_time": "2021-12-23T19:51:24.369118Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = ConvAct(1, 16)\n",
    "        self.conv2 = ConvAct(16, 32)\n",
    "        self.conv3 = ConvAct(32, 64, dropout=0.2)\n",
    "        self.conv4 = ConvAct(64, 128, dropout=0.2)\n",
    "        self.conv5 = ConvAct(128, 256, dropout=0.2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = LinearAct(in_features=3072, out_features=512, dropout=0.7)\n",
    "        self.fc2 = LinearAct(in_features=512, out_features=256, dropout=0.5)\n",
    "        self.fc3 = LinearAct(in_features=256, out_features=64, dropout=0.3)\n",
    "        self.fc4 = LinearAct(in_features=64, out_features=len(classes), output_layer=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0626050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.510150Z",
     "start_time": "2021-12-23T19:51:24.384125Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "gamma = 0.98\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=len(train_dataset), gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model, criterion = model.to(device), criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627dd15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:24.621175Z",
     "start_time": "2021-12-23T19:51:24.513150Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualising learning rate per epoch\n",
    "learning_rates = [lr]\n",
    "for x in range(1, epochs):\n",
    "    learning_rates.append(learning_rates[x-1] * gamma)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(learning_rates, color='black', label='learning rate', linestyle='--')\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"learning rate every epoch\")\n",
    "plt.tight_layout()\n",
    "plt.margins(x=0.01, y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49daff92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:29.026310Z",
     "start_time": "2021-12-23T19:51:24.622176Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(model, (1, *IMG_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1aa323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:29.042316Z",
     "start_time": "2021-12-23T19:51:29.028309Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91517f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:29.058323Z",
     "start_time": "2021-12-23T19:51:29.044311Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_per_epoch_train, loss_per_epoch_train = [], []\n",
    "accuracy_per_epoch_val, loss_per_epoch_val = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cc184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:52:46.763239Z",
     "start_time": "2021-12-23T19:52:44.418858Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    print(f\"Epoch: {epoch}/{epochs}\")\n",
    "    \n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = len(train_dataset)\n",
    "    correct_training_predictions = 0\n",
    "    train_tqdm = tqdm(train_dataset, total=batch_size, colour='black')\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for (x, y) in train_tqdm:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(x).double().cpu()\n",
    "        loss = criterion(pred.to(device), y)\n",
    "\n",
    "        predictions = pred.argmax(1).int()\n",
    "        y = torch.Tensor(y.tolist()).int()\n",
    "\n",
    "        correct_training_predictions += (predictions == y).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append((correct_training_predictions / train_images) * 100)\n",
    "\n",
    "        average_train_accuracy = round(sum(train_accuracies) / len(train_accuracies), 4)\n",
    "        average_train_loss = round(sum(train_losses) / len(train_losses), 4)\n",
    "        train_tqdm.set_description(f\"Training Avg Loss: {average_train_loss} || Avg Acc: {average_train_accuracy}%\")\n",
    "\n",
    "\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct_eval_predictions = 0\n",
    "\n",
    "        val_tqdm = tqdm(val_dataset, total=len(val_dataset), colour='black')\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        for (x, y) in val_tqdm:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            pred = model(x).double().cpu()\n",
    "            loss = criterion(pred.to(device), y)\n",
    "\n",
    "            predictions = pred.argmax(1).int()\n",
    "            y = torch.Tensor(y.tolist()).int()\n",
    "\n",
    "            correct_eval_predictions += (predictions == y).sum().item()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_accuracies.append((correct_eval_predictions / validation_images) * 100)\n",
    "\n",
    "            average_val_accuracy = round(sum(val_accuracies) / len(val_accuracies), 4)\n",
    "            average_val_loss = round(sum(val_losses) / len(val_losses), 4)\n",
    "\n",
    "            val_tqdm.set_description(f\"Validation Avg Loss: {average_val_loss} || Avg Acc: {average_val_accuracy}%\")\n",
    "    print(\"\\n===========================================================================================================\\\n",
    "====================\\n\")\n",
    "    # STORING TRAIN AND VALIDATION AVERAGE ACCURACIES AND LOSSES PER EPOCH\n",
    "    accuracy_per_epoch_train.append(average_train_accuracy)\n",
    "    accuracy_per_epoch_val.append(average_val_accuracy)\n",
    "    \n",
    "    loss_per_epoch_train.append(average_train_loss)\n",
    "    loss_per_epoch_train.append(average_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f39cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:30.519266Z",
     "start_time": "2021-12-23T19:51:30.519266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_images = len(test_dataset)\n",
    "test_tqdm = tqdm(test_dataset, total=len(test_dataset), colour='black')\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct_test_predictions = 0\n",
    "\n",
    "    for (x, y) in test_tqdm:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        pred = model(x).double().cpu()\n",
    "        loss = criterion(pred.to(device), y)\n",
    "\n",
    "        predictions = pred.argmax(1).int()\n",
    "        y = torch.Tensor(y.tolist()).int()\n",
    "\n",
    "        correct_test_predictions = (predictions == y).sum().item()\n",
    "\n",
    "        test_losses.append(loss.item())\n",
    "        test_accuracies.append((correct_test_predictions / test_images) * 100)\n",
    "\n",
    "        average_test_accuracy = round(sum(test_accuracies) / len(test_accuracies), 4)\n",
    "        average_test_loss = round(sum(test_losses) / len(test_losses), 4)\n",
    "\n",
    "        test_tqdm.set_description(f\"Test Avg Loss: {average_test_loss} || Avg Acc: {average_test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb027a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T19:51:30.520267Z",
     "start_time": "2021-12-23T19:51:30.520267Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "ax[0].set_title(f\"Avg Test Acc: {sum(test_accuracies) / len(test_accuracies):.4f}%\")\n",
    "ax[0].plot(accuracy_per_epoch_train, color=\"black\", linestyle=\"--\", label=\"Training Accuracy\")\n",
    "ax[0].plot(accuracy_per_epoch_val, color=\"green\", linestyle=\"--\", label=\"Training Validation\")\n",
    "ax[0].fill_between(x=range(epochs), y1=accuracy_per_epoch_train, y2=accuracy_per_epoch_val, color=\"cyan\", alpha=0.2)\n",
    "ax[0].axhline(sum(test_accuracies) / len(test_accuracies), label=\"Test Accruacy\")\n",
    "ax[0].margins(x=0.01, y=0.01)\n",
    "ax[0].legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "ax[1].set_title(f\"Avg Loss: {sum(test_losses) / len(test_losses):.4f}\")\n",
    "ax[1].plot(loss_per_epoch_train, color=\"black\", linestyle=\"--\", label=\"Training Loss\")\n",
    "ax[1].plot(loss_per_epoch_val, color=\"green\", linestyle=\"--\", label=\"Validation Loss\")\n",
    "ax[1].fill_between(x=range(epochs), y1=loss_per_epoch_train, y2=loss_per_epoch_val, color=\"cyan\", alpha=0.2)\n",
    "ax[1].axhline(sum(test_losses) / len(test_losses), label=\"Test Loss\")\n",
    "ax[1].margins(x=0.01, y=0.01)\n",
    "ax[1].legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
